{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "T.b.d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import functools\n",
    "from typing import Callable\n",
    "from itertools import accumulate\n",
    "from copy import deepcopy\n",
    "from operator import xor\n",
    "from collections import namedtuple\n",
    "\n",
    "TUNING = False\n",
    "CODE_FOR_TABLE = False\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n",
    "Move = namedtuple(\"Move\", \"row num_objects fitness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIM Game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i*2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self._rows}\"\n",
    "\n",
    "    def nimming(self, row: int, num_objects: int) -> None:\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        assert num_objects > 0, f\"You have to pick at least one\"\n",
    "        self._rows[row] -= num_objects\n",
    "        if sum(self._rows) == 0:\n",
    "            logging.debug(\"Yeuch\")\n",
    "    \n",
    "    def nimming2(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        assert num_objects > 0, f\"You have to pick at least one\"\n",
    "        self._rows[row] -= num_objects\n",
    "\n",
    "    @property\n",
    "    def rows(self):\n",
    "        return self._rows\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(rows: list) -> int:\n",
    "    # List XOR\n",
    "    # Using reduce() + lambda + \"^\" operator\n",
    "    res = functools.reduce(lambda x, y: x ^ y, rows)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament(population, tournament_size=2):\n",
    "    return min(random.choices(population, k=tournament_size), key=lambda i: i.fitness)\n",
    "\n",
    "def mutation(p: Move, nim: Nim):\n",
    "    if nim.k is None:\n",
    "        elements = random.randrange(1, nim.rows[p.row] + 1)\n",
    "        temp_rows = nim.rows.copy()\n",
    "        temp_rows[p.row] -=elements \n",
    "        offspring = Move(p.row, elements , nim_sum(temp_rows))\n",
    "    else:\n",
    "        elements = min(nim.k, random.randrange(1, nim.rows[p.row] + 1))\n",
    "        temp_rows = nim.rows.copy()\n",
    "        temp_rows[p.row] -=elements \n",
    "        offspring = Move(p.row, elements , nim_sum(temp_rows))\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def cross_over(p1: Move, p2: Move, nim: Nim):\n",
    "\n",
    "    n_random = random.randint(0, 1)\n",
    "    \n",
    "    if n_random == 0:\n",
    "\n",
    "        temp_rows = nim.rows.copy()\n",
    "        temp_rows[p1.row] -= p2.num_objects\n",
    "\n",
    "        if temp_rows[p1.row] < 0:\n",
    "            return None\n",
    "\n",
    "        offspring = Move(p1.row, p2.num_objects , nim_sum(temp_rows))\n",
    "    else:\n",
    "        temp_rows = nim.rows.copy()\n",
    "        temp_rows[p2.row] -= p1.num_objects\n",
    "\n",
    "        if temp_rows[p2.row] < 0:\n",
    "            return None\n",
    "\n",
    "        offspring = Move(p2.row, p1.num_objects , nim_sum(temp_rows))\n",
    "    \n",
    "    if nim.k is not None and offspring.num_objects > nim.k:\n",
    "        return None\n",
    "\n",
    "    return offspring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3.2: An agent using Evolved Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the NIM Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 3\n",
    "GAMEOVER = [0 for _ in range(N_ROWS)]\n",
    "POPULATION_SIZE = 10\n",
    "OFFSPRING_SIZE = 10\n",
    "N_GENERATIONS = 20\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state.rows)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming2(m)\n",
    "        brute_force.append((m, nim_sum(tmp.rows)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    possible_new_states = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "            tmp = deepcopy(state)\n",
    "            tmp.nimming2(m)\n",
    "            possible_new_states.append((tmp, m))\n",
    "    cooked[\"possible_new_states\"] = possible_new_states\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategies:\n",
    "\n",
    "* Task 3.1 (_Expert System_) : _Best Possibile Strategy_ implemented in `best_strategy` and nominated as `best` (see below). To understand the algorithm of the winning strategy, look at [*Nim*](https://en.wikipedia.org/wiki/Nim)!\n",
    "* Task 3.1 Bis (_Expert System_) : _Fixed Rules I would play_ implemented in `evolvable_based_on_fixed_rules`  but using $\\alpha = 0.5$ and $\\beta = 0.5$ and nominated as `evolvable`.\n",
    "* Task 3.2 (_Evolvable Strategies_): _Evolvable Strategies based on GA_ implemented in `evolvable_based_on_GA` and nominated as `ga`.\n",
    "* Task 3.2 bis (_Evolvable Strategies_): _Evolvable Strategies based on Fixed Rules_ implemented in `evolvable_based_on_fixed_rules`  but using $\\alpha = 0.4$ and $\\beta = 0.1$ (best parameters found when playing against a pure random opponent and using a random $K$) and nominated as `evolvable`.\n",
    "* Other strategies:\n",
    "  * Best strategy By [Prof. Squillero](https://github.com/squillero) implemented in `best_strategy_by_prof` and nominated as `best_prof`.\n",
    "  * Evolvable strategy By [Prof. Squillero](https://github.com/squillero) implemented in `evolvable_by_prof` and nominated as `evolvable_prof`.\n",
    "\n",
    "To use this strategies, use their nomination (e.g. `best`, `evolvable`, ... ) in the `evaulate` function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, strategy = 'best') -> None:\n",
    "        # Two parts for the best strategy:\n",
    "        # 0 -> before all rows have one element\n",
    "        # 1 -> after all rows have one element\n",
    "        self._best_strategy = 0\n",
    "\n",
    "        assert strategy in ['best', 'best_prof', 'pure_random', 'ga', 'evolvable', 'evolvable_prof', 'evolvable_tuned', 'min_max'], f\"Strategy non-available\"\n",
    "        self._strategy = strategy\n",
    "\n",
    "    def moves(self, Nim, alpha = 0.5, beta = 0.5):\n",
    "        if self._strategy == 'best':\n",
    "            return self.best_strategy(Nim)\n",
    "        elif self._strategy == 'best_prof':\n",
    "            return self.best_strategy_by_prof(Nim)\n",
    "        elif self._strategy == 'pure_random':\n",
    "            return self.pure_random(Nim)\n",
    "        elif self._strategy == 'ga':\n",
    "            return self.evolvable_based_on_GA(Nim)\n",
    "        elif self._strategy == 'evolvable':\n",
    "            return self.evolvable_based_on_fixed_rules(Nim, cook_status(Nim), alpha, beta)\n",
    "        elif self._strategy == 'evolvable_tuned':\n",
    "            return self.evolvable_based_on_fixed_rules(Nim, cook_status(Nim), 0.4, 0.1)\n",
    "        elif self._strategy == 'evolvable_prof':\n",
    "            return self.evolvable_by_prof(Nim, alpha)\n",
    "        elif self._strategy == 'min_max':\n",
    "            return self.min_max_best_move(Nim)\n",
    "        else: \n",
    "            assert f\"Can't use a strategy\"\n",
    "        return\n",
    "\n",
    "\n",
    "    def pure_random(self, Nim):\n",
    "\n",
    "        # The opponent choose randomly a non-empty row \n",
    "        nonzeroind = np.nonzero(Nim.rows)[0]\n",
    "        random_row = random.choice(nonzeroind)\n",
    "\n",
    "        # The opponen choose to remove a random number of elements\n",
    "        if Nim._k == None:\n",
    "            random_elements = random.randint(1,Nim.rows[random_row])\n",
    "        else:\n",
    "            random_elements = random.randint(1,min(Nim._k,Nim.rows[random_row]))\n",
    "\n",
    "        return Nimply(random_row, random_elements)\n",
    "\n",
    "        \n",
    "    def best_strategy(self, Nim):\n",
    "\n",
    "        # If all the elements are equal or less then k, we can play the 'normal' nim game\n",
    "        if Nim._k != None and all(v <= Nim._k for v in Nim.rows):\n",
    "            temp_k = None\n",
    "        else:\n",
    "            temp_k = Nim._k\n",
    "\n",
    "        if temp_k != None:\n",
    "\n",
    "            # Try brute force:\n",
    "            for ind, row in enumerate(Nim.rows):\n",
    "\n",
    "                for el in range(1, min(row + 1, Nim._k + 1)):\n",
    "                    # Reset temp_rows\n",
    "                    temp_rows = Nim.rows.copy()\n",
    "                    \n",
    "                    # See if nim_sum == 0\n",
    "                    temp_rows[ind] -= el\n",
    "                    if nim_sum(temp_rows) == 0:\n",
    "                        # Update table\n",
    "                        # Nim.nimming(ind, el)\n",
    "                        return Nimply(ind, el)\n",
    "            \n",
    "            equal_grater_than_k_ind = [i for i,v in enumerate(Nim.rows) if v >= Nim._k + 1]\n",
    "            \n",
    "            random_row = random.choice(equal_grater_than_k_ind)\n",
    "            elements = Nim.rows[random_row]%(Nim._k+1) \n",
    "            \n",
    "            if elements == 0:\n",
    "                elements = 1\n",
    "\n",
    "            return Nimply(random_row, elements)\n",
    "\n",
    "        # If there is only one element greater to one, the agent picks a number of object to make\n",
    "        # all the rows of the table equal to 1.\n",
    "        # He can choose to remove all the objects or all the objects but one from the rows with n>1\n",
    "        if sum(x >= 2 for x in Nim.rows) == 1:\n",
    "            # Row with more than one element\n",
    "            equal_grater_than_two_ind = [i for i,v in enumerate(Nim.rows) if v >= 2][0]\n",
    "\n",
    "            # Change of strategy\n",
    "            self._best_strategy = 1\n",
    "\n",
    "            \n",
    "            # To win, the remaing number of objects has to be even \n",
    "            if (sum(x for x in Nim.rows) - Nim.rows[equal_grater_than_two_ind]) % 2 == 0 :\n",
    "        \n",
    "                return Nimply(equal_grater_than_two_ind, Nim.rows[equal_grater_than_two_ind])\n",
    "                \n",
    "            else:\n",
    "\n",
    "                return Nimply(equal_grater_than_two_ind, Nim.rows[equal_grater_than_two_ind]-1)        \n",
    "        \n",
    "        # Strategy before all rows have one element\n",
    "        if self._best_strategy == 0:    \n",
    "        \n",
    "            res = nim_sum(Nim.rows)\n",
    "\n",
    "            for ind, row in enumerate(Nim.rows):\n",
    "\n",
    "                if row == 0:\n",
    "                    continue\n",
    "\n",
    "                if row ^ res < row:\n",
    "                   \n",
    "                    elements = row - (row ^ res)\n",
    "\n",
    "                    return Nimply(ind, elements)\n",
    "        \n",
    "        # Strategy after all rows have one element\n",
    "        else:\n",
    "\n",
    "            nonzeroind = [i for i, e in enumerate(Nim.rows) if e != 0]\n",
    "            random_row = random.choice(nonzeroind)\n",
    "\n",
    "            return Nimply(random_row, 1) \n",
    "                 \n",
    "        # Default move -> Random\n",
    "        nonzeroind = [i for i, e in enumerate(Nim.rows) if e != 0]\n",
    "        random_row = random.choice(nonzeroind)\n",
    "\n",
    "        if Nim._k == None:\n",
    "            random_elements = random.randrange(1,Nim.rows[random_row] + 1)\n",
    "        else:\n",
    "            random_elements = random.randrange(1,min(Nim._k,Nim.rows[random_row])+1)\n",
    "\n",
    "          \n",
    "        return Nimply(random_row, random_elements) \n",
    "\n",
    "    def best_strategy_by_prof(self, state: Nim):\n",
    "        data = cook_status(state)\n",
    "        move  = next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]\n",
    "        return Nimply(move[0], move[1])\n",
    "\n",
    "    def evolvable_by_prof(self, state: Nim, p = 0.5):\n",
    "        data = cook_status(state)\n",
    "\n",
    "        if random.random() < p:\n",
    "            if state.k is not None:\n",
    "                ply = Nimply(data[\"shortest_row\"], min(state.k, random.randint(1, state.rows[data[\"shortest_row\"]])))\n",
    "            else:\n",
    "                ply = Nimply(data[\"shortest_row\"], random.randint(1, state.rows[data[\"shortest_row\"]]))\n",
    "\n",
    "        else:\n",
    "            if state.k is not None:\n",
    "                ply = Nimply(data[\"longest_row\"], min(state.k,random.randint(1, state.rows[data[\"longest_row\"]])))\n",
    "            else:\n",
    "                ply = Nimply(data[\"longest_row\"], random.randint(1, state.rows[data[\"longest_row\"]]))\n",
    "\n",
    "        return ply\n",
    "    \n",
    "    def evolvable_based_on_fixed_rules(self, state: Nim, cook_status: dict, alpha: float = 0.5, beta: float = 0.5):\n",
    "        initial_numbers = sum([i*2 + 1 for i in range(N_ROWS)])\n",
    "        actual_numbers = sum(state.rows)\n",
    "\n",
    "        # Early game strategy\n",
    "        if actual_numbers > alpha * initial_numbers:\n",
    "            \n",
    "            if cook_status['active_rows_number'] >= beta*N_ROWS:\n",
    "\n",
    "                row = cook_status[\"longest_row\"]\n",
    "                if state.k is not None:\n",
    "                    elements = min(state.k, state.rows[row])\n",
    "                    if elements == 0:\n",
    "                        print(\"1\")\n",
    "                else:\n",
    "                    elements = state.rows[row]\n",
    "                    if elements == 0:\n",
    "                        print(\"2\")\n",
    "                # state.nimming(row, elements)\n",
    "                return Nimply(row, elements)\n",
    "\n",
    "        row = cook_status[\"longest_row\"]\n",
    "\n",
    "        if cook_status[\"active_rows_number\"]%2 == 0 and state.rows[row]!=1 :\n",
    "            if state.k is not None:\n",
    "                #Leave at least one element\n",
    "                elements = min( (state.k - 1), state.rows[row] - 1)\n",
    "        \n",
    "            else:\n",
    "                #Leave at least one element\n",
    "                elements = state.rows[row] - 1\n",
    "\n",
    "        else:\n",
    "            if state.k is not None:\n",
    "                #Try to remove the maximum number of elements\n",
    "                elements = min(state.k, state.rows[row])\n",
    "            else:\n",
    "                #Try to remove the maximum number of elements\n",
    "                elements = state.rows[row]\n",
    "        \n",
    "        if elements == 0:\n",
    "            elements = 1\n",
    "        # state.nimming(row, elements)\n",
    "        return Nimply(row, elements)\n",
    "        \n",
    "    def evolvable_based_on_GA(self, state: Nim):\n",
    "        \n",
    "        # Population = possible moves\n",
    "        population = []\n",
    "        for _ in range(POPULATION_SIZE):\n",
    "            # temp_rows needed to evaluate nim_sum = fitness (low nim_sum is better!)\n",
    "            temp_rows = state.rows.copy()\n",
    "\n",
    "            # Choosing a random_row\n",
    "            nonzeroind = [i for i, e in enumerate(state.rows) if e != 0]\n",
    "            random_row = random.choice(nonzeroind)\n",
    "\n",
    "            #Choosing a random_move\n",
    "            if state.k is None:\n",
    "                random_elements = random.randrange(1, state.rows[random_row] + 1)\n",
    "\n",
    "            else:\n",
    "                random_elements =  min(random.randrange(1, state.rows[random_row] + 1), state.k)\n",
    "\n",
    "            temp_rows[random_row] -= random_elements\n",
    "            fitness = nim_sum(temp_rows)\n",
    "            pop = Move(random_row, random_elements, fitness)\n",
    "            population.append(pop)\n",
    "        \n",
    "\n",
    "        for g in range(N_GENERATIONS):\n",
    "            offspring = list()\n",
    "            for i in range(OFFSPRING_SIZE):\n",
    "\n",
    "                if random.random() < 0.5:\n",
    "                    # Selection of parents\n",
    "                    p = tournament(population.copy())\n",
    "\n",
    "                    # Offspring generation\n",
    "                    o = mutation(p, state)       \n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    p1 = tournament(population)\n",
    "                    p2 = tournament(population)\n",
    "                    o = cross_over(p1, p2, state)\n",
    "\n",
    "                # Check if cross-over returned a valid solution.\n",
    "                # In this code, only valid solutions has been considered.\n",
    "                # Possible Improvement: Acceptance with penalties of non-valid solutions\n",
    "                if o == None:\n",
    "                    continue\n",
    "\n",
    "                offspring.append(o)\n",
    "            \n",
    "            # Adding new Offspings generated to Population list\n",
    "            population+=offspring\n",
    "            \n",
    "            # Sorting the Population, according to their fitness and selecting the firsts n_elements = POPULATION_SIZE\n",
    "            population = sorted(population, key=lambda i: i.fitness, reverse=False)[:POPULATION_SIZE]\n",
    "            logging.debug(f\"actual best {population[0]}\")\n",
    "        \n",
    "        return Nimply(population[0].row, population[0].num_objects)\n",
    "\n",
    "    # Internal function\n",
    "    def _minimax(self, state: Nim, maximizing: int = True):\n",
    "        \n",
    "        # Check the result of the previous move\n",
    "        if state.rows == GAMEOVER:\n",
    "            # The player who made the previous move has already won\n",
    "            return -1 if maximizing else 1\n",
    "\n",
    "        cooked = cook_status(state)\n",
    "\n",
    "        scores = [\n",
    "                self._minimax(new_state, maximizing = not maximizing)\n",
    "                for new_state, move in cooked[\"possible_new_states\"]\n",
    "                ]\n",
    "        return (max if maximizing else min)(scores)\n",
    "    \n",
    "    def min_max_best_move(self, state: Nim):\n",
    "        cooked = cook_status(state)\n",
    "        ply = None\n",
    "        for new_state, move in cooked[\"possible_new_states\"]:\n",
    "    \n",
    "            score = self._minimax(new_state, maximizing = False)\n",
    "\n",
    "            if score > 0:\n",
    "                ply = Nimply(move[0], move[1])\n",
    "                break\n",
    "        \n",
    "        if ply is None:\n",
    "            logging.debug(\" No winning moves :(\")\n",
    "            nonzeroind = [i for i, e in enumerate(state.rows) if e != 0]\n",
    "            random_row = random.choice(nonzeroind)\n",
    "\n",
    "            ply =  Nimply(random_row, 1)\n",
    "            \n",
    "        return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES = 3\n",
    "\n",
    "def evaluate(agent_strategy = 'best', opponent_strategy = 'pure_random', parameter_dict: dict = {\"alpha\": None, \"beta\": None}) -> float:\n",
    "    \n",
    "    won = 0\n",
    "    start = 0\n",
    "\n",
    "    for m in range(NUM_MATCHES):\n",
    "        agent = Player(agent_strategy)\n",
    "        opponent = Player(opponent_strategy)\n",
    "\n",
    "        # K = random.randint(0, 100)\n",
    "        K = 3\n",
    "        if K == 0:\n",
    "            K = None\n",
    "        # Nim Table Creation    \n",
    "        nim = Nim(N_ROWS, K)\n",
    "        \n",
    "        # 0 -> Agent's turn\n",
    "        # 1 -> Opponent's turn\n",
    "        turn = start\n",
    "\n",
    "        # the first move is equally distributed within matches\n",
    "        start = 1 - start \n",
    "        \n",
    "        # turn = random.randint(0,1)\n",
    "\n",
    "        logging.debug(f\"\\n\\n\\n--------NEW GAME---------\")\n",
    "        # Game\n",
    "        while nim._rows != GAMEOVER:\n",
    "            if turn == 0:\n",
    "                logging.debug(f\" Actual turn: Agent\")\n",
    "            else:\n",
    "                logging.debug(f\" Actual turn: Opponent\")\n",
    "\n",
    "            logging.debug(f\" \\tTable before move: {nim} and Nim_sum: {nim_sum(nim._rows)}\")\n",
    "            \n",
    "            if turn == 0:\n",
    "                if agent_strategy == 'evolvable':\n",
    "                    assert parameter_dict['alpha'] is not None, f\"Please choose a value for alfa\"\n",
    "                    assert parameter_dict['beta'] is not None, f\"Please choose a value for beta\"\n",
    "                    ply = agent.moves(nim, parameter_dict['alpha'], parameter_dict['beta'] )\n",
    "                    \n",
    "\n",
    "                elif agent_strategy == 'evolvable_by_prof':\n",
    "                    assert parameter_dict['alpha'] is not None, f\"Please choose a value for alfa\"\n",
    "                    ply = agent.moves(nim, parameter_dict['alpha'])\n",
    "                else:\n",
    "                    ply = agent.moves(nim)\n",
    "                \n",
    "                logging.debug(f\" \\tAgent:   <Row: {ply.row}- Elements: {ply.num_objects}>\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if opponent_strategy == 'evolvable':\n",
    "                    assert parameter_dict['alpha_opp'] is not None, f\"Please choose a value for alfa used by the opponent -> 'alpha_opp'\"\n",
    "                    assert parameter_dict['beta_opp'] is not None, f\"Please choose a value for beta used by the opponent -> 'beta_opp'\"\n",
    "                    ply = opponent.moves(nim, parameter_dict['alpha_opp'], parameter_dict['beta_opp'] )\n",
    "\n",
    "                elif opponent_strategy == 'evolvable_by_prof':\n",
    "                    assert parameter_dict['alpha_opp'] is not None, f\"Please choose a value for alfa used by the opponent -> 'alpha_opp'\"\n",
    "                    ply = opponent.moves(nim, parameter_dict['alpha_opp'])\n",
    "\n",
    "                else:\n",
    "                    ply = opponent.moves(nim)\n",
    "                \n",
    "                logging.debug(f\" \\tOpponent:   <Row: {ply.row}- Elements: {ply.num_objects}>\")\n",
    "            if ply.num_objects == 0:\n",
    "                print(f\"turn = {turn} \")\n",
    "            nim.nimming2(ply)\n",
    "            logging.debug(f\" \\tTable after move: {nim} and Nim_sum: {nim_sum(nim._rows)}\\n\")\n",
    "\n",
    "            \n",
    "            turn = 1 - turn\n",
    "        \n",
    "        logging.debug(f\"--------GAME OVER---------\")\n",
    "        # Game Over\n",
    "        if turn == 1:\n",
    "            won +=1\n",
    "        else:\n",
    "            logging.debug(f\"Game Lost by the agent is the n°{m}\")\n",
    "            \n",
    "        \n",
    "    return won / NUM_MATCHES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of $\\alpha$ and $\\beta$ for taks 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "if TUNING:\n",
    "    max_win_rate = 0\n",
    "\n",
    "    # Value to test\n",
    "    values = list(x/10 for x in range(1, 10, 1))\n",
    "\n",
    "    parameter_dict= {}\n",
    "\n",
    "    for alpha in values:\n",
    "        for beta in values:\n",
    "        \n",
    "            parameter_dict[\"alpha\"] = alpha\n",
    "            parameter_dict[\"beta\"] = beta\n",
    "\n",
    "            act_won_rate = evaluate(agent_strategy='evolvable', opponent_strategy='pure_random', parameter_dict = parameter_dict)\n",
    "\n",
    "            if act_won_rate > max_win_rate:\n",
    "                alpha_best = alpha\n",
    "                beta_best = beta\n",
    "                max_win_rate = act_won_rate\n",
    "\n",
    "                logging.debug(f\" Found a new configuration:\\n\\talpha = {alpha_best}\\n\\tbeta = {beta_best}\\n\\twon rate = {max_win_rate}\")\n",
    "\n",
    "    \n",
    "    logging.info(f\"\\nBest configuration:\\n\\talpha = {alpha_best}\\n\\tbeta = {beta_best}\\n\\twon rate = {max_win_rate}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:\n",
      "\n",
      "\n",
      "--------NEW GAME---------\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [1, 3, 5] and Nim_sum: 7\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (0, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 2)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 3)\n",
      "DEBUG:root: \tAgent:   <Row: 1- Elements: 3>\n",
      "DEBUG:root: \tTable after move: [1, 0, 5] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [1, 0, 5] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 0- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 5] and Nim_sum: 5\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 5] and Nim_sum: 5\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 4] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [0, 0, 4] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 3] and Nim_sum: 3\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 3] and Nim_sum: 3\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 2)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 3)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 3>\n",
      "DEBUG:root: \tTable after move: [0, 0, 0] and Nim_sum: 0\n",
      "\n",
      "DEBUG:root:--------GAME OVER---------\n",
      "DEBUG:root:\n",
      "\n",
      "\n",
      "--------NEW GAME---------\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [1, 3, 5] and Nim_sum: 7\n",
      "DEBUG:root: \tOpponent:   <Row: 0- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 3, 5] and Nim_sum: 6\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 3, 5] and Nim_sum: 6\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 2)\n",
      "DEBUG:root: \tAgent:   <Row: 1- Elements: 2>\n",
      "DEBUG:root: \tTable after move: [0, 1, 5] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [0, 1, 5] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 1- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 5] and Nim_sum: 5\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 5] and Nim_sum: 5\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 4] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [0, 0, 4] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 3] and Nim_sum: 3\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 3] and Nim_sum: 3\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 2)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 3)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 3>\n",
      "DEBUG:root: \tTable after move: [0, 0, 0] and Nim_sum: 0\n",
      "\n",
      "DEBUG:root:--------GAME OVER---------\n",
      "DEBUG:root:\n",
      "\n",
      "\n",
      "--------NEW GAME---------\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [1, 3, 5] and Nim_sum: 7\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (0, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 2)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (1, 3)\n",
      "DEBUG:root: \tAgent:   <Row: 1- Elements: 3>\n",
      "DEBUG:root: \tTable after move: [1, 0, 5] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [1, 0, 5] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 0- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 5] and Nim_sum: 5\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 5] and Nim_sum: 5\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 4] and Nim_sum: 4\n",
      "\n",
      "DEBUG:root: Actual turn: Opponent\n",
      "DEBUG:root: \tTable before move: [0, 0, 4] and Nim_sum: 4\n",
      "DEBUG:root: \tOpponent:   <Row: 2- Elements: 1>\n",
      "DEBUG:root: \tTable after move: [0, 0, 3] and Nim_sum: 3\n",
      "\n",
      "DEBUG:root: Actual turn: Agent\n",
      "DEBUG:root: \tTable before move: [0, 0, 3] and Nim_sum: 3\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 1)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 2)\n",
      "DEBUG:root:new_state = <class '__main__.Nim'> and mov = (2, 3)\n",
      "DEBUG:root: \tAgent:   <Row: 2- Elements: 3>\n",
      "DEBUG:root: \tTable after move: [0, 0, 0] and Nim_sum: 0\n",
      "\n",
      "DEBUG:root:--------GAME OVER---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Won: 100.0% of the games\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "parameter_dict= {}\n",
    "\n",
    "# Insert here your own parameters\n",
    "# Best values of alpha and beta against a pure random opponent are respectively 0.4 and 0.1 generally\n",
    "\n",
    "parameter_dict[\"alpha\"] = 0.4\n",
    "parameter_dict[\"beta\"] = 0.1\n",
    "parameter_dict[\"alpha_opp\"] = 0.99\n",
    "parameter_dict[\"beta_opp\"] = 0.1\n",
    "\n",
    "# Evaluation Section:\n",
    "\n",
    "# print(f\"Agent Won: {evaluate()*100}% of the games\")\n",
    "# print(f\"Agent Won: {evaluate(agent_strategy='best_prof')*100}% of the games\")\n",
    "# print(f\"Agent Won: {evaluate(agent_strategy='best', opponent_strategy='best_prof')*100}% of the games\")\n",
    "# print(f\"Agent Won: {evaluate(agent_strategy='ga', opponent_strategy='best_prof')*100}% of the games\")\n",
    "# print(f\"Agent Won: {evaluate(agent_strategy='evolvable', opponent_strategy='evolvable', parameter_dict = parameter_dict)*100}% of the games\")\n",
    "# print(f\"Agent Won: {evaluate(agent_strategy='evolvable', opponent_strategy='pure_random', parameter_dict = parameter_dict)*100}% of the games\")\n",
    "print(f\"Agent Won: {evaluate(agent_strategy='min_max', opponent_strategy='pure_random', parameter_dict = parameter_dict)*100}% of the games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results For Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CODE_FOR_TABLE:\n",
    "    strategies = ['pure_random', 'best', 'best_prof', 'evolvable', 'evolvable_tuned', 'ga','evolvable_prof' ]\n",
    "    parameter_dict= {}\n",
    "    parameter_dict[\"alpha\"] = 0.5\n",
    "    parameter_dict[\"beta\"] = 0.5\n",
    "    parameter_dict[\"alpha_opp\"] = 0.5\n",
    "    parameter_dict[\"beta_opp\"] = 0.5\n",
    "    for agent in strategies:\n",
    "        for opponent in strategies:\n",
    "            print(f\"Agent Strategy: {agent} Opponent Strategy: {opponent} -> Agent Won: {evaluate(agent_strategy= agent, opponent_strategy=opponent, parameter_dict = parameter_dict)*100}% of the games \")\n",
    "            # print(f\"{agent} - {opponent} - {evaluate(agent_strategy= agent, opponent_strategy=opponent, parameter_dict = parameter_dict)*100}% of the games \")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
